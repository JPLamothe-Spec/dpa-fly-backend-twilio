// index.js â€” Twilio PSTN â†” OpenAI Realtime (Î¼-law)
// Baseline + surgical stability fixes:
// - No-empty-commit fuse (watermarking new audio)
// - Longer trickle cadence & cooldown
// - Higher min-bytes & hard ms floor
// - Same behavior otherwise (ASR trickle always on, pause commits, transcripts)

const express = require("express");
const http = require("http");
const WebSocket = require("ws");
const bodyParser = require("body-parser");
require("dotenv").config();

// ---- Env & defaults
const PORT = Number(process.env.PORT || 3000);
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const REALTIME_MODEL = process.env.OPENAI_REALTIME_MODEL || "gpt-4o-realtime-preview-2024-12-17";
const VOICE = (process.env.VOICE || "coral").toLowerCase();

// ASR must be one of: whisper-1, gpt-4o-transcribe, gpt-4o-mini-transcribe
const TRANSCRIBE_MODEL_RAW = (process.env.OPENAI_TRANSCRIBE_MODEL || "gpt-4o-mini-transcribe").trim();
const ALLOWED_ASR = new Set(["whisper-1", "gpt-4o-transcribe", "gpt-4o-mini-transcribe"]);
const TRANSCRIBE_MODEL = ALLOWED_ASR.has(TRANSCRIBE_MODEL_RAW) ? TRANSCRIBE_MODEL_RAW : "gpt-4o-mini-transcribe";

const DEV_MODE = String(process.env.ANNA_DEV_MODE || "true").toLowerCase() === "true";
const DEV_CALLER_NAME = process.env.DEV_CALLER_NAME || "JP";

// Î¼-law @8k: 160B â‰ˆ 20ms, 800B â‰ˆ 100ms (API minimum)
const DEFAULT_MIN_COMMIT_BYTES = 1600; // â‰ˆ200ms floor (raised from 800)
const MIN_COMMIT_BYTES = Number(process.env.MIN_COMMIT_BYTES || DEFAULT_MIN_COMMIT_BYTES);
const MIN_COMMIT_MS_HARD = 140; // never commit <140ms even if bytes suggest otherwise

// ---- VAD knobs (tunable via env) â€” unchanged defaults, just exposed
const SPEECH_THRESH = Number(process.env.VAD_SPEECH_THRESH || 18);
const SILENCE_MS    = Number(process.env.VAD_SILENCE_MS || 550);
const MAX_TURN_MS   = Number(process.env.VAD_MAX_TURN_MS || 3200);

// ---- ASR â€œtrickleâ€ (always on) to surface ðŸ‘‚ YOU SAID continuously (no model reply)
// Cadence & cooldown relaxed to avoid double-commit races seen in logs
const TRICKLE_MS         = Number(process.env.VAD_TRICKLE_MS || 900); // was 600
const COMMIT_COOLDOWN_MS = Number(process.env.COMMIT_COOLDOWN_MS || 800); // was 300

const PROJECT_BRIEF = process.env.PROJECT_BRIEF || `Digital Personal Assistant (DPA)
- Goal: natural, low-latency phone assistant for JP.
- Priorities: realtime voice, AU/UK female voice, no unsolicited number capture, low latency, smooth barge-in.
- Dev mode: treat caller as JP (teammate). Be concise, flag latency/transcription issues, suggest next tests.`;

// quick Î¼-law energy proxy
function ulawEnergy(buf){ let s=0; for (let i=0;i<buf.length;i++) s+=Math.abs(buf[i]-0x7f); return s/buf.length; }

// TwiML generator (keeps your prior shape)
function twiml(wsUrl) {
  return `
<Response>
  <Connect>
    <Stream url="${wsUrl}" track="inbound_track"/>
  </Connect>
  <Pause length="30"/>
</Response>`.trim();
}

const app = express();
app.use(bodyParser.urlencoded({ extended: false }));
app.use(bodyParser.json());

// --- Twilio webhook ---
app.post("/twilio/voice", (req, res) => {
  const streamUrl = (process.env.PUBLIC_WS_URL || "").trim() || `wss://${req.headers.host}/call`;
  console.log("âž¡ï¸ /twilio/voice hit (POST)");
  const xml = twiml(streamUrl);
  console.log("ðŸ§¾ TwiML returned:", xml);
  res.type("text/xml").send(xml);
});
app.get("/twilio/voice", (req, res) => {
  const streamUrl = (process.env.PUBLIC_WS_URL || "").trim() || `wss://${req.headers.host}/call`;
  console.log("âž¡ï¸ /twilio/voice hit (GET)");
  const xml = twiml(streamUrl);
  console.log("ðŸ§¾ TwiML returned:", xml);
  res.type("text/xml").send(xml);
});

app.get("/", (_req, res) => res.status(200).send("Realtime DPA backend is live"));
app.get("/health", (_req, res) => res.status(200).send("ok"));

const server = http.createServer(app);
const wss = new WebSocket.Server({ noServer: true });

// --- Upgrade diagnostics ---
server.on("upgrade", (req, socket, head) => {
  console.log("ðŸ›° HTTP upgrade requested:", req.method, req.url);
  if (req.url === "/call") {
    wss.handleUpgrade(req, socket, head, (ws) => wss.emit("connection", ws, req));
  } else {
    console.log("ðŸš« Upgrade path not /call â€” closing");
    try { socket.destroy(); } catch {}
  }
});

// --- Bridge Twilio <-> OpenAI Realtime ---
wss.on("connection", async (twilioWS, req) => {
  const ip = req.headers["x-forwarded-for"] || req.socket.remoteAddress;
  console.log("âœ… Twilio WebSocket connected from", ip);

  if (!OPENAI_API_KEY) {
    console.error("âŒ OPENAI_API_KEY not set â€” closing");
    try { twilioWS.close(); } catch {}
    return;
  }

  const oai = new WebSocket(
    `wss://api.openai.com/v1/realtime?model=${encodeURIComponent(REALTIME_MODEL)}`,
    {
      headers: {
        Authorization: `Bearer ${OPENAI_API_KEY}`,
        "OpenAI-Beta": "realtime=v1",
        "openai-beta": "realtime=v1",
      }
    }
  );

  let streamSid = null;
  let mulawChunks = [];
  let bytesBuffered = 0;
  let lastSpeechAt = Date.now();
  let turnStartedAt = Date.now();
  let mediaPackets = 0;

  // Session health & response gating
  let socketOpen = false;
  let sessionHealthy = false;
  let sessionError = false;
  let activeResponse = false;

  // Commit guards
  let lastCommitAt = 0;
  let commitInflight = false;
  let lastTrickleAt = 0;

  // Transcript accumulators
  let callerText = "";
  let assistantText = "";

  // NEW: watermark counters to prevent empty commits
  let totalAppendedBytes = 0; // ever-increasing since stream start
  let lastCommittedBytes = 0; // watermark snapshot at last successful commit

  const resetBuffer = () => { mulawChunks = []; bytesBuffered = 0; };
  const nowMs = () => Date.now();
  const bufferedMs = (bytes) => Math.round((bytes / 800) * 100); // Î¼-law @8k

  function canCommit() {
    if (!socketOpen || !sessionHealthy || sessionError) return false;
    if (commitInflight) return false;
    if (nowMs() - lastCommitAt < COMMIT_COOLDOWN_MS) return false;

    // No-new-audio fuse: block commit if nothing has been appended since last commit
    if (totalAppendedBytes <= lastCommittedBytes) return false;

    if (bytesBuffered < MIN_COMMIT_BYTES) return false;
    if (mulawChunks.length === 0) return false;
    return true;
  }

  function doCommit({ respond, cause }) {
    if (!canCommit()) return;

    const payloadBuf = Buffer.concat(mulawChunks);
    const ms = bufferedMs(payloadBuf.length);
    if (ms < MIN_COMMIT_MS_HARD) {
      // Too short â€” skip silently to avoid server-side rounding to <100ms
      return;
    }

    const b64 = payloadBuf.toString("base64");
    commitInflight = true;
    lastCommitAt = nowMs();

    try {
      oai.send(JSON.stringify({ type: "input_audio_buffer.append", audio: b64 }));
      // Advance watermark *just before* commit; if commit fails we attempt to roll back
      lastCommittedBytes = totalAppendedBytes;
      oai.send(JSON.stringify({ type: "input_audio_buffer.commit" }));

      if (respond && !activeResponse) {
        oai.send(JSON.stringify({ type: "response.create", response: { modalities: ["audio","text"] } }));
        activeResponse = true; // optimistic until response.created
        console.log(`ðŸ”Š committed ~${ms}ms cause=${cause} (â†’ respond)`);
      } else {
        console.log(`ðŸ”Š committed ~${ms}ms cause=${cause} (no respond)`);
      }

      // On a turn commit, flush caller turn summary line
      if (respond && callerText.trim()) {
        console.log("ðŸ‘‚ YOU (turn):", callerText.trim());
        callerText = "";
      }
    } catch (e) {
      console.error("âŒ send to Realtime failed:", e?.message || e);
      // Best-effort rollback of watermark to allow future commit
      lastCommittedBytes = Math.max(0, lastCommittedBytes - payloadBuf.length);
    } finally {
      commitInflight = false;
      resetBuffer();
      turnStartedAt = nowMs();
    }
  }

  function commitTrickle() {
    // ASR-only trickle so we always get ðŸ‘‚ YOU SAID deltas, even while Anna is speaking
    if (!canCommit()) return;
    if (nowMs() - lastTrickleAt < TRICKLE_MS) return;
    lastTrickleAt = nowMs();
    doCommit({ respond: false, cause: "trickle" });
  }

  oai.on("open", () => {
    socketOpen = true;
    console.log("ðŸ”— OpenAI Realtime connected");

    const instructions = DEV_MODE
      ? `You are Anna, JPâ€™s English-accented digital personal assistant AND a core member of the DPA build team.
Caller is ${DEV_CALLER_NAME}. Be concise. Avoid asking for phone numbers unless requested.

PROJECT BRIEF:
${PROJECT_BRIEF}`
      : `You are Anna, JPâ€™s assistant on a live phone call. Be concise and helpful.`;

    // Configure session: Î¼-law in/out + ASR model
    const sessionUpdate = {
      type: "session.update",
      session: {
        input_audio_format:  "g711_ulaw",
        output_audio_format: "g711_ulaw",
        modalities: ["audio","text"],
        voice: VOICE,
        instructions,
        input_audio_transcription: { model: TRANSCRIBE_MODEL }
      }
    };

    try {
      oai.send(JSON.stringify(sessionUpdate));
    } catch (e) {
      console.error("âŒ session.update send failed:", e?.message || e);
    }

    // Single greeting once session is valid
    setTimeout(() => {
      if (!sessionError) {
        try {
          oai.send(JSON.stringify({
            type: "response.create",
            response: { modalities: ["audio","text"], instructions: "Hiâ€”how can I help?" }
          }));
          activeResponse = true; // optimistic until response.created arrives
        } catch (e) {
          console.error("âŒ greeting send failed:", e?.message || e);
        }
      }
    }, 120);
  });

  oai.on("error", (e) => console.error("ðŸ”» OAI socket error:", e?.message || e));
  oai.on("close", (c, r) => console.log("ðŸ”š OAI socket closed", c, r?.toString?.() || ""));

  // ---- OpenAI -> Twilio + Logs ----
  oai.on("message", (buf) => {
    let msg; try { msg = JSON.parse(buf.toString()); } catch { return; }

    // Session health
    if (msg.type === "session.updated") {
      sessionHealthy = true;
      console.log(`âœ… session.updated (ASR=${TRANSCRIBE_MODEL})`);
      return;
    }

    if (msg.type === "error") {
      console.error("ðŸ”» OAI error:", msg);
      const p = msg?.error?.param || "";
      if (String(p).startsWith("session.") || ["invalid_value","missing_required_parameter"].includes(msg?.error?.code)) {
        sessionError = true;
      }
      // We don't close on input_audio_buffer_commit_empty anymore; watermark guard should prevent it.
      return;
    }

    // Response lifecycle (prevents duplicate response.create)
    if (msg.type === "response.created") { activeResponse = true; return; }
    if (msg.type === "response.completed" || msg.type === "response.output_audio.done" || msg.type === "response.refusal.delta") {
      activeResponse = false;
      // Flush assistant turn summary line
      if (assistantText.trim()) console.log("ðŸ—£ï¸ ANNA (turn):", assistantText.trim());
      assistantText = "";
      return;
    }

    // Assistant transcript (delta/streaming)
    if (msg.type === "response.audio_transcript.delta" && msg.delta) {
      assistantText += String(msg.delta);
      console.log("ðŸ—£ï¸ ANNA SAID:", String(msg.delta));
      return;
    }

    // Caller transcripts (arrive after each commit)
    if (msg.type === "response.input_audio_transcription.delta" && msg.delta) {
      callerText += String(msg.delta);
      console.log("ðŸ‘‚ YOU SAID:", String(msg.delta));
      return;
    }
    if (msg.type === "response.input_text.delta" && msg.delta) {
      callerText += String(msg.delta);
      console.log("ðŸ‘‚ YOU SAID (text):", String(msg.delta));
      return;
    }

    // Forward assistant audio to Twilio (Î¼-law already, thanks to output_audio_format)
    if (streamSid) {
      if (msg.type === "response.audio.delta" && msg.delta) {
        try {
          twilioWS.send(JSON.stringify({ event: "media", streamSid, media: { payload: msg.delta } }));
        } catch (e) { console.error("âŒ send audio to Twilio failed:", e?.message || e); }
        return;
      }
      if (msg.type === "response.output_audio.delta" && msg.audio) {
        try {
          twilioWS.send(JSON.stringify({ event: "media", streamSid, media: { payload: msg.audio } }));
        } catch (e) { console.error("âŒ send audio to Twilio failed:", e?.message || e); }
        return;
      }
      if (msg.type === "response.audio.done" || msg.type === "response.output_audio.done") {
        try { twilioWS.send(JSON.stringify({ event: "mark", streamSid, mark: { name: "tts-done" } })); } catch {}
        return;
      }
    }
  });

  // ---- VAD/turn-taking + ASR trickle ----
  const vadPoll = setInterval(() => {
    if (!socketOpen || !sessionHealthy || sessionError) return;

    const t = nowMs();
    const longSilence = t - lastSpeechAt >= SILENCE_MS;
    const hitMax = t - turnStartedAt >= MAX_TURN_MS;

    // (A) Short pause or max-turn â†’ real turn commit (ask to respond if free)
    if ((longSilence || hitMax) && bytesBuffered >= MIN_COMMIT_BYTES) {
      doCommit({ respond: !activeResponse, cause: hitMax ? "max" : "silence" });
      return;
    }

    // (B) While caller is talking â†’ periodic ASR-only trickles so you see ðŸ‘‚ deltas
    if (bytesBuffered >= MIN_COMMIT_BYTES) {
      commitTrickle();
    }
  }, 50);

  // Twilio inbound media
  twilioWS.on("message", (raw) => {
    let data; try { data = JSON.parse(raw.toString()); } catch { return; }
    switch (data.event) {
      case "connected":
        console.log("ðŸ“ž Twilio media stream connected");
        break;

      case "start":
        streamSid = data.start?.streamSid || null;
        console.log(`ðŸŽ¬ Twilio stream START: streamSid=${streamSid}, voice=${VOICE}, model=${REALTIME_MODEL}, dev=${DEV_MODE}`);
        resetBuffer();
        mediaPackets = 0;
        lastSpeechAt = nowMs();
        turnStartedAt = nowMs();
        lastCommitAt = 0;
        lastTrickleAt = 0;
        callerText = "";
        assistantText = "";
        // reset watermarks
        totalAppendedBytes = 0;
        lastCommittedBytes = 0;
        break;

      case "media": {
        const b64 = data?.media?.payload; if (!b64) break;
        const mulaw = Buffer.from(b64, "base64");  // Î¼-law 8k, 160B â‰ˆ 20ms
        mediaPackets += 1;
        if (mediaPackets <= 5 || mediaPackets % 50 === 0) console.log(`ðŸŸ¢ media pkt #${mediaPackets} (+${mulaw.length} bytes)`);
        const e = ulawEnergy(mulaw);
        if (e > SPEECH_THRESH) lastSpeechAt = nowMs();
        mulawChunks.push(mulaw);
        bytesBuffered += mulaw.length;
        totalAppendedBytes += mulaw.length; // NEW: mark new audio since last commit
        break;
      }

      case "mark":
        break;

      case "stop":
        console.log("ðŸ›‘ Twilio STOP event");
        // Final ASR-only commit to flush any tail audio, but don't request reply
        doCommit({ respond: false, cause: "stop" });
        cleanup();
        break;

      default:
        console.log("â„¹ï¸ Twilio event:", data.event);
    }
  });

  twilioWS.on("close", () => { console.log("âŒ Twilio WS closed"); cleanup(); });
  twilioWS.on("error", (err) => { console.error("âš ï¸ Twilio WS error:", err?.message || err); cleanup(); });

  function cleanup(){
    try { clearInterval(vadPoll); } catch {}
    try { if (oai.readyState === WebSocket.OPEN) oai.close(); } catch {}
    try { if (twilioWS.readyState === WebSocket.OPEN) twilioWS.close(); } catch {}
  }
});

server.listen(PORT, "0.0.0.0", () => {
  console.log(`ðŸš€ Realtime DPA listening on 0.0.0.0:${PORT}`);
});
server.on("clientError", (err, socket) => {
  console.error("ðŸ’¥ HTTP clientError:", err?.message || err);
  try { socket.destroy(); } catch {}
});
